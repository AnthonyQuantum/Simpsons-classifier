{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Simpsons_GH.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LzWQ6W-uVRAh","colab_type":"text"},"source":["# **Simpsons classifier**\n","*By Vizgalov_Anton*\n","\n","---\n","\n","Разобрал пример из baseline, получил маленький score, решил взять предобученную Resnet-152 и сделать fine-tuning.\n","\n","Экспериментировал с аугментацией картинок через imgaug, но score это не улучшало, поэтому в финальной версии ее убрал.\n"," \n"," *На Kaggle получил private score = 0.94092*\n","\n"," Часть кода взята из https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n"]},{"cell_type":"code","metadata":{"id":"Qcu_CgeVQ4sP","colab_type":"code","colab":{}},"source":["# установить необходимые модули\n","\n","!pip install -U torch numpy torchvision matplotlib pandas sklearn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l4i1Hnk5R1E6","colab_type":"code","colab":{}},"source":["# примонтировать Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRZTqW5-ah6X","colab_type":"code","colab":{}},"source":["# Для обучения используется расширенный датасет, в который были добавлены\n","# картинки для редких классов. Картинки получал путем image scraping-а по\n","# Google Images. На валидации результат улучшился значительно, но\n","# на тесте почти не изменился.\n","#\n","# Датасет скачивается отдельно.\n","!unzip -q /content/drive/My\\ Drive/Simpsons/data/trainset.zip\n","\n","# тестовый датасет без изменений\n","!unzip -q /content/drive/My\\ Drive/simpsons/data/testset.zip -d test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxYU8ZRLRgdy","colab_type":"code","colab":{}},"source":["# подключить необходимые модули\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support as score\n","import warnings\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","import os\n","import copy\n","import random\n","\n","plt.ion()   # interactive mode"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KANBUr82RmML","colab_type":"code","colab":{}},"source":["# Приведение картинок к нужному размеру, нормализация и простейшая аугментация.\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9wHOkZErJ0M","colab_type":"code","outputId":"f407fe20-855c-48f1-867b-3a0b18e2353d","executionInfo":{"status":"ok","timestamp":1578676689733,"user_tz":-180,"elapsed":783,"user":{"displayName":"Anthony Quantum","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mACeyl4UUsUKZ6kTpi8cWTSgESn-OQRP1-_FuXN=s64","userId":"16770810684194748412"}},"colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["# папка с датасетами\n","data_dir = '/content/drive/My Drive/Simpsons/data'\n","\n","# прочитать и сохранить названия файлов из тестового датасета (пригодится для\n","# формирования таблички submission.csv)\n","files_list = []\n","for r, d, files in os.walk(data_dir + '/test'):\n","  files_list.extend(files)\n","sorted_files = sorted(files_list)\n","\n","# вывести статистику по числу файлов на каждый класс (помогает узнать какие\n","# классы редкие)\n","file_num_info = [(len(files), r) for r, d, files in os.walk(data_dir + '/train')]\n","for num, file in sorted(file_num_info, key=lambda x: x[0]):\n","  print(num, '|', file.split('/')[-1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 | train\n","27 | fat_tony\n","27 | gil\n","32 | otto_mann\n","40 | sideshow_mel\n","41 | agnes_skinner\n","42 | disco_stu\n","45 | rainier_wolfcastle\n","47 | cletus_spuckler\n","49 | miss_hoover\n","55 | snake_jailbird\n","56 | troy_mcclure\n","57 | lionel_hutz\n","65 | professor_john_frink\n","71 | martin_prince\n","82 | patty_bouvier\n","89 | ralph_wiggum\n","98 | carl_carlson\n","106 | barney_gumble\n","117 | selma_bouvier\n","121 | groundskeeper_willie\n","128 | maggie_simpson\n","181 | waylon_smithers\n","246 | mayor_quimby\n","310 | lenny_leonard\n","358 | nelson_muntz\n","457 | edna_krabappel\n","469 | comic_book_guy\n","498 | kent_brockman\n","623 | apu_nahasapeemapetilon\n","877 | sideshow_bob\n","904 | abraham_grampa_simpson\n","986 | chief_wiggum\n","1079 | milhouse_van_houten\n","1193 | charles_montgomery_burns\n","1194 | principal_skinner\n","1206 | krusty_the_clown\n","1291 | marge_simpson\n","1342 | bart_simpson\n","1354 | lisa_simpson\n","1452 | moe_szyslak\n","1454 | ned_flanders\n","2246 | homer_simpson\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rMylACqLRdqk","outputId":"15bce0b5-9193-43c4-c3ad-7b754687a7cf","executionInfo":{"status":"ok","timestamp":1578676694395,"user_tz":-180,"elapsed":1118,"user":{"displayName":"Anthony Quantum","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mACeyl4UUsUKZ6kTpi8cWTSgESn-OQRP1-_FuXN=s64","userId":"16770810684194748412"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# датасеты\n","train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n","                                     data_transforms['train'])\n","val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n","                                     data_transforms['val'])\n","test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'),\n","                                     data_transforms['test'])\n","\n","# перемешать индексы для того чтобы картинки брались в случайном порядке\n","indices = list(range(len(train_dataset)))\n","random.shuffle(indices)\n","train_indices, val_indices = indices[len(indices)//4:], indices[:len(indices)//4]\n","\n","# сэмплеры\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","# индексы для тест-сета, уже без перемешивания\n","test_indices = list(range(len(test_dataset)))\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","# лоадеры\n","# batch_size=32 оказался оптимальным\n","dataloaders = {'train': torch.utils.data.DataLoader(train_dataset,\n","                                                    sampler=train_sampler,\n","                                                    batch_size=32),\n","               'val': torch.utils.data.DataLoader(val_dataset,\n","                                                  sampler=val_sampler,\n","                                                  batch_size=32),\n","               'test': torch.utils.data.DataLoader(test_dataset,\n","                                                   sampler=test_sampler,\n","                                                   batch_size=1)\n","               }\n","\n","# конечные размеры датасетов\n","dataset_sizes = {'train': len(train_indices),\n","                 'val': len(val_indices),\n","                 'test': len(test_indices)}\n","\n","# названия классов и их количество\n","class_names = train_dataset.classes\n","num_classes = len(class_names)\n","\n","# выбор устройства для запуска (предпочтительно GPU)\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda:0\")\n","  print('Training on GPU')\n","else:\n","  device = torch.device(\"cpu\")\n","  print('Training on CPU')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training on GPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AjgmAY-gZIZT","colab_type":"code","colab":{}},"source":["# функция обучения модели\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            print('Start {} phase'.format(phase))\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            i = 1\n","            for inputs, labels in dataloaders[phase]:\n","                # показывает сколько батчей уже обработано\n","                print('Processing input #{} of {} [{:4f}%]' \\\n","                  .format(i, len(dataloaders[phase]), i/len(dataloaders[phase])*100))\n","                i += 1\n","\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rUzy9aKs3gB_","colab_type":"code","colab":{}},"source":["# используется предобученная Resnet-152\n","model_ft = models.resnet152(pretrained=True)\n","num_ftrs = model_ft.fc.in_features\n","\n","# добавляется слой, соответствующий числу классов (у нас 42)\n","model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","\n","model_ft = model_ft.to(device)\n","criterion = nn.CrossEntropyLoss()\n","\n","# в основном использовал lr=0.001, но lr=0.0001 в некоторых экспериментах\n","# помогал улучшить результат\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-A6iMIlyDCp","colab_type":"code","colab":{}},"source":["# Загрузить сохраненные веса.\n","\n","model_ft.load_state_dict(torch.load(\"/content/drive/My Drive/Simpsons/model_weights_extdataset_12epoch.pth\"))\n","model_ft.eval() # переключаем нейросеть в режим обучения"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBolS1rS36RH","colab_type":"code","colab":{}},"source":["# обучение модели (оптимально 10-12 эпох)\n","model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n","                       num_epochs=12)\n","\n","# сохранение весов\n","model_weights = copy.deepcopy(model_ft.state_dict())\n","torch.save(model_weights, \"model_weights_new.pth\") "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nk-K9BFaULuG","colab_type":"text"},"source":["## **Calculate F1 score**"]},{"cell_type":"code","metadata":{"id":"UnCGdLSB6Fjp","colab_type":"code","colab":{}},"source":["# функция для получения результата классификации\n","\n","def predict(model, test_loader):\n","    with torch.no_grad():\n","        logits = []\n","\n","        i = 1   \n","        for inputs in test_loader:\n","            # выводит информацию о прогрессе\n","            print('Predicting #{} of {}'.format(i, len(test_loader)))\n","            i += 1\n","            \n","            inputs = inputs.to(device)\n","            model.eval()\n","            outputs = model(inputs).cpu()\n","            logits.append(outputs)\n","            \n","    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n","    return probs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L79WTkR_6eEI","colab_type":"code","colab":{}},"source":["# берутся все картинки из валидационного сета и для них\n","# проводится классификация\n","\n","imgs = [val_dataset[id][0].unsqueeze(0) for id in val_indices]\n","probs_ims = predict(model_ft, imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0NP3tCK6p0s","colab_type":"code","colab":{}},"source":["# берется top-1 prediction для каждой картинки, затем каждому индексу класса\n","# сопоставляется слово - название класса\n","\n","y_pred = np.argmax(probs_ims, -1)\n","actual_labels = [val_dataset[id][1] for id in val_indices]\n","preds_class = [class_names[i] for i in y_pred]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHQavdWv6r33","colab_type":"code","outputId":"9422f3b2-c556-4abd-e4c0-b0971d34fa36","executionInfo":{"status":"ok","timestamp":1578673049790,"user_tz":-180,"elapsed":576,"user":{"displayName":"Anthony Quantum","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mACeyl4UUsUKZ6kTpi8cWTSgESn-OQRP1-_FuXN=s64","userId":"16770810684194748412"}},"colab":{"base_uri":"https://localhost:8080/","height":867}},"source":["with warnings.catch_warnings():     # отключаются предупреждения о \"нулевых\"\n","  warnings.simplefilter(\"ignore\")   # предсказаниях\n","  print('Score:', f1_score(actual_labels,                     # выводится f1-\n","                           y_pred,                            # score и отчет\n","                           labels=np.unique(actual_labels),   # по конкретным\n","                           average='macro'))                  # классам\n","  print(classification_report(actual_labels, y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Score: 0.9599636662734239\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       218\n","           1       1.00      0.75      0.86        12\n","           2       1.00      1.00      1.00       155\n","           3       1.00      0.93      0.96        29\n","           4       1.00      1.00      1.00       355\n","           5       1.00      1.00      1.00        21\n","           6       0.98      0.98      0.98       299\n","           7       0.98      1.00      0.99       232\n","           8       1.00      0.89      0.94         9\n","           9       0.97      0.99      0.98       127\n","          10       1.00      1.00      1.00        11\n","          11       0.97      0.99      0.98       109\n","          12       1.00      1.00      1.00         6\n","          13       1.00      0.20      0.33         5\n","          14       1.00      0.97      0.98        30\n","          15       0.99      0.99      0.99       548\n","          16       1.00      0.99      0.99       144\n","          17       0.99      0.99      0.99       321\n","          18       0.99      0.99      0.99        78\n","          19       1.00      0.92      0.96        12\n","          20       0.98      1.00      0.99       323\n","          21       1.00      0.88      0.93        32\n","          22       0.99      0.99      0.99       325\n","          23       1.00      0.95      0.97        20\n","          24       0.97      0.95      0.96        62\n","          25       0.99      1.00      0.99       262\n","          26       0.90      0.90      0.90        10\n","          27       0.99      0.99      0.99       362\n","          28       0.99      0.99      0.99       379\n","          29       0.99      0.99      0.99        84\n","          30       1.00      0.90      0.95        10\n","          31       0.86      0.92      0.89        13\n","          32       0.97      1.00      0.99       286\n","          33       1.00      0.96      0.98        23\n","          34       1.00      1.00      1.00        11\n","          35       1.00      1.00      1.00        21\n","          36       0.97      0.95      0.96        37\n","          37       1.00      1.00      1.00       212\n","          38       1.00      1.00      1.00        10\n","          39       1.00      1.00      1.00        13\n","          40       0.94      1.00      0.97        16\n","          41       0.92      0.98      0.95        46\n","\n","    accuracy                           0.99      5278\n","   macro avg       0.98      0.95      0.96      5278\n","weighted avg       0.99      0.99      0.99      5278\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ngNOp7jU778","colab_type":"text"},"source":["## **Submit to Kaggle**"]},{"cell_type":"code","metadata":{"id":"jEAS-ejCapDD","colab_type":"code","colab":{}},"source":["# загрузить картинки из тестового датасета\n","\n","test_imgs = [test_dataset[id][0].unsqueeze(0)\n","             for id in range(len(test_dataset))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQHLvuaKVBAu","colab_type":"code","colab":{}},"source":["# сделать классификацию для каждой картинки\n","probs = predict(model_ft, test_imgs)\n","\n","# взять top-1 predictions\n","preds = [class_names[i] for i in np.argmax(probs, axis=1)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ns1Xkd48VI_6","colab_type":"code","outputId":"bc78cc25-bfc7-4296-db70-4312af1e1a28","executionInfo":{"status":"ok","timestamp":1578504826968,"user_tz":-180,"elapsed":539,"user":{"displayName":"Anthony Quantum","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mACeyl4UUsUKZ6kTpi8cWTSgESn-OQRP1-_FuXN=s64","userId":"16770810684194748412"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# получить имена файлов картинок\n","test_filenames = [name for name in sorted_files]\n","\n","# сопоставить имена файлов и результаты классификации\n","results = [(sorted_files[i], preds[i]) for i in range(len(sorted_files))]\n","results.sort(key=lambda x: int(x[0][3:-4]))\n","\n","# сформировать итоговую таблицу и вывести ее первые несколько значений\n","my_submit = pd.DataFrame({'Id': [res[0] for res in results],\n","                          'Expected': [res[1] for res in results]})\n","my_submit.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Expected</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>img0.jpg</td>\n","      <td>nelson_muntz</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>img1.jpg</td>\n","      <td>bart_simpson</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>img2.jpg</td>\n","      <td>edna_krabappel</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>img3.jpg</td>\n","      <td>nelson_muntz</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>img4.jpg</td>\n","      <td>lisa_simpson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Id        Expected\n","0  img0.jpg    nelson_muntz\n","1  img1.jpg    bart_simpson\n","2  img2.jpg  edna_krabappel\n","3  img3.jpg    nelson_muntz\n","4  img4.jpg    lisa_simpson"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"XfchX3wMVLxm","colab_type":"code","colab":{}},"source":["# сохранить таблицу\n","\n","my_submit.to_csv('drive/My Drive/Simpsons/new_submission.csv', index=False)"],"execution_count":0,"outputs":[]}]}